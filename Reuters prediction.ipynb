{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task:\n",
    "\n",
    "- use Keras :)\n",
    "- **build simple network with single hidden layer to classify text to one of 46 classes**\n",
    "- plot confusion matrix\n",
    "- experiment with parameters to get better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n",
    "                                                         test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11228"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test) + len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n"
     ]
    }
   ],
   "source": [
    "print(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12],\n",
       "       [1, 2, 699, 2, 2, 56, 2, 2, 9, 56, 2, 2, 81, 5, 2, 57, 366, 737, 132, 20, 2, 7, 2, 49, 2, 2, 2, 2, 699, 2, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2, 2, 2, 775, 7, 48, 34, 191, 44, 35, 2, 505, 17, 12],\n",
       "       [1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 2, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 2, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 2, 55, 2, 92, 617, 80, 2, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 2, 7, 2, 81, 5, 187, 11, 15, 9, 2, 201, 5, 47, 2, 18, 478, 2, 5, 2, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12],\n",
       "       ...,\n",
       "       [1, 141, 2, 387, 81, 8, 16, 2, 10, 340, 2, 850, 31, 56, 2, 691, 9, 2, 71, 9, 2, 2, 2, 699, 2, 2, 2, 699, 244, 2, 4, 49, 8, 4, 656, 850, 33, 2, 9, 2, 340, 2, 2, 9, 2, 22, 2, 2, 687, 83, 35, 15, 257, 6, 57, 2, 7, 4, 2, 654, 5, 2, 2, 2, 4, 49, 8, 16, 369, 646, 6, 2, 7, 124, 407, 17, 12],\n",
       "       [1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 2, 18, 14, 74, 134, 2, 18, 88, 2, 72, 11, 14, 2, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 2, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 2, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 2, 137, 336, 2, 6, 2, 142, 971, 2, 43, 359, 5, 4, 326, 753, 364, 17, 12],\n",
       "       [1, 227, 2, 91, 2, 125, 2, 21, 4, 2, 76, 7, 4, 757, 481, 2, 790, 2, 2, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 2, 91, 2, 2, 340, 7, 194, 2, 6, 2, 21, 127, 2, 2, 2, 6, 2, 4, 329, 433, 7, 65, 87, 2, 10, 2, 2, 290, 9, 21, 567, 16, 2, 24, 4, 76, 209, 30, 2, 2, 2, 8, 4, 60, 8, 4, 966, 308, 40, 2, 129, 2, 295, 277, 2, 9, 24, 286, 2, 234, 222, 9, 4, 906, 2, 2, 114, 2, 2, 7, 4, 113, 17, 12]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint\n",
    "\n",
    "Use tokenizer class to change training data IDs to matrix with position IDs, where e.g.\n",
    "\n",
    "number \"10\" becomes \"1\" on 11th position in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
