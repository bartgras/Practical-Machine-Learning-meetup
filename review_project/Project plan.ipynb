{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please don't edit this notebook during meetup session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fast.ai - notebooks\n",
    "\n",
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson1.ipynb\n",
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson2.ipynb\n",
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson3.ipynb\n",
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson4.ipynb\n",
    "\n",
    "## fast.ai - lesson notes\n",
    "\n",
    "- http://wiki.fast.ai/index.php/Lesson_1_Notes\n",
    "- http://wiki.fast.ai/index.php/Lesson_2_Notes\n",
    "- http://wiki.fast.ai/index.php/Lesson_3_Notes\n",
    "- http://wiki.fast.ai/index.php/Lesson_4_Notes\n",
    "\n",
    "## Project data \n",
    "\n",
    "#### State Farm Distracted Driver Detection\n",
    "\n",
    "Source: https://www.kaggle.com/c/state-farm-distracted-driver-detection\n",
    "\n",
    "Folder with 79.726 (train) and 3.436.108 (test) images\n",
    "\n",
    "- 10 classes:\n",
    "- c1: texting - right\n",
    "- c2: talking on the phone - right\n",
    "- c3: texting - left\n",
    "- c4: talking on the phone - left\n",
    "- c5: operating the radio\n",
    "- c6: drinking\n",
    "- c7: reaching behind\n",
    "- c8: hair and makeup\n",
    "- c9: talking to passenger\n",
    "\n",
    "\n",
    "# Project plan\n",
    "\n",
    "- 20-30 minutes: Together go through notebooks (Fast.ai lesson 1 to 4) and pick things related to this project\n",
    "- 5-10 minutes: Divide picked items into: data preprocessing, model, training process, validation of results\n",
    "- <5 minutes: split into teams\n",
    "- <10 minutes: plan what what are inputs and outputs of each team and communicate that to other teams\n",
    "- - quick and dirty inputs: what team before me could prepare so that I could run/test my part\n",
    "- 1-1.5 hours: build each teamâ€™s part\n",
    "- <10 minutes: merge results into single notebook and run\n",
    "- do test run to see preliminary results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes - theory\n",
    "\n",
    "\n",
    "## Preprocessing\n",
    "- divide images into folders training/valid/test and 1 per class\n",
    "-- pick random images from each class folder, so that we have more/less equal ratio on input\n",
    "- validate images\n",
    "- resize (try different sizes), use rectangular images?\n",
    "- look at the random samples of the images\n",
    "- - check if all \"action\" is in the middle of image\n",
    "- prepare sample set (subset of all train/test images)\n",
    "- put VGG weigths into file ??\n",
    "- use Keras image generator\n",
    "- split train/valid with ratio 0.3 ; prepare 2 separate inputs for model\n",
    "- use cats and dogs and shuffle images for train/valid \n",
    "- use notebook magic functions to move images around \n",
    "-- remember to do it as a last step of preprocessing\n",
    "-- check if keras image preprocessing function can shuffle and create 2 separate sets (train/valid)\n",
    "\n",
    "\n",
    "## Define a model\n",
    "### Inputs\n",
    "- (original size is 640x480) dimentions: 3x224x224 / 3x224x(?) (ratio: 3/4) \n",
    "\n",
    "### Hidden layers\n",
    "\n",
    "Create model from scratch\n",
    "1. start with single convolution\n",
    "2. because image is color, use 3 layers in convolution\n",
    "\n",
    "###### ResNET\n",
    "\n",
    "ResNET with added layer at the end (notebook lesson 7)\n",
    "remember we can't use Max Pooling\n",
    "\n",
    "###### VGG\n",
    "\n",
    "- VGG / VGG with batchnorm \n",
    "- remove last layer and change it to output 10\n",
    "\n",
    "#### Outputs \n",
    "- 10 classes\n",
    "\n",
    "#### Training\n",
    "- start with Adam optimizer\n",
    "- \n",
    "\n",
    "\n",
    "### Trained model\n",
    "- See which predictions we are confident about (and the other way around)\n",
    "- Visualize the ouput to see predicted classes\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
